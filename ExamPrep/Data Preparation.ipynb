{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 From .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('CarPrice_Assignment.csv',delimiter = ',')\n",
    "\n",
    "# print(data)\n",
    "# headers = data[0,:]\n",
    "# print(headers)\n",
    "# data = data[1:,:]\n",
    "# print(data[:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 From sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 From .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata is imported as numpy array, do not forget to remove the header\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = np.genfromtxt('Housing_data.txt',delimiter = ',', dtype=str);\n",
    "'''\n",
    "data is imported as numpy array, do not forget to remove the header\n",
    "'''\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract X and y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract x\n",
    "# col = ['enginesize','horsepower','peakrpm']\n",
    "# X = data[col]\n",
    "# print(X.iloc[:5,:])\n",
    "\n",
    "# # extract y\n",
    "# y = data['price'] \n",
    "# print(y.iloc[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Sklearn Datasets (Bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers and data\n",
    "# headers = raw_data[0,:];\n",
    "# print(headers)\n",
    "# data = np.array(raw_data[1:,:], dtype=float);\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # see headers\n",
    "# headers = data[0,:]\n",
    "# print(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Shape Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  506\n",
      "Number of features:  13\n"
     ]
    }
   ],
   "source": [
    "# check number of samples\n",
    "m = X.shape[0]\n",
    "print(\"Number of samples: \", m)\n",
    "# check number of features\n",
    "n = X.shape[1]\n",
    "print(\"Number of features: \", n)\n",
    "\n",
    "# check number of y\n",
    "assert m == y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1 Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values for train data:\n",
      "------------------------\n",
      " 0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Pandas \n",
    "#Convert to DataFrame to check for missing data\n",
    "df = pd.DataFrame(X)\n",
    "print('Missing values for train data:\\n------------------------\\n', df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2 Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.2.1 Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Yes and No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_train['Married'].value_counts())\n",
    "\n",
    "# married = data_train['Married'].value_counts()\n",
    "# print('Elements in Married variable', married.shape)\n",
    "# print('Married ratio ', married[0]/sum(married.values))\n",
    "\n",
    "# def fill_martial_status(data, yes_num_train, no_num_train):        \n",
    "#     data['Married'].fillna('Yes', inplace = True, limit = yes_num_train)\n",
    "#     data['Married'].fillna('No', inplace = True, limit = no_num_train)  \n",
    "\n",
    "# fill_martial_status(data_train, 2, 1)\n",
    "# print(data_train['Married'].value_counts()) \n",
    "# print('Missing values for train data:\\n------------------------\\n', data_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_train['Dependents'].value_counts())\n",
    "# dependent = data_train['Dependents'].value_counts()\n",
    "\n",
    "# print('Dependent ratio 1 ', dependent['0'] / sum(dependent.values))\n",
    "# print('Dependent ratio 2 ', dependent['1'] / sum(dependent.values))\n",
    "# print('Dependent ratio 3 ', dependent['2'] / sum(dependent.values))\n",
    "# print('Dependent ratio 3+ ', dependent['3+'] / sum(dependent.values))\n",
    "\n",
    "# def fill_dependent_status(num_0_train, num_1_train, num_2_train, num_3_train, num_0_test, num_1_test, num_2_test, num_3_test):        \n",
    "#     data_train['Dependents'].fillna('0', inplace=True, limit = num_0_train)\n",
    "#     data_train['Dependents'].fillna('1', inplace=True, limit = num_1_train)\n",
    "#     data_train['Dependents'].fillna('2', inplace=True, limit = num_2_train)\n",
    "#     data_train['Dependents'].fillna('3+', inplace=True, limit = num_3_train)\n",
    "#     data_test['Dependents'].fillna('0', inplace=True, limit = num_0_test)\n",
    "#     data_test['Dependents'].fillna('1', inplace=True, limit = num_1_test)\n",
    "#     data_test['Dependents'].fillna('2', inplace=True, limit = num_2_test)\n",
    "#     data_test['Dependents'].fillna('3+', inplace=True, limit = num_3_test)\n",
    "\n",
    "# fill_dependent_status(9, 2, 2, 2, 5, 2, 2, 1)\n",
    "\n",
    "# print(data_train['Dependents'].value_counts())\n",
    "\n",
    "# # Convert category value \"3+\" to \"4\"\n",
    "\n",
    "# data_train['Dependents'].replace('3+', 4, inplace = True)\n",
    "# data_test['Dependents'].replace('3+', 4, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 Continuous (filled with mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data_train['LoanAmount'].value_counts())\n",
    "\n",
    "# LoanAmt = data_train['LoanAmount'].value_counts()\n",
    "\n",
    "# print('mean loan amount ', np.mean(data_train[\"LoanAmount\"]))\n",
    "\n",
    "# loan_amount_mean = np.mean(data_train[\"LoanAmount\"])\n",
    "\n",
    "# data_train['LoanAmount'].fillna(loan_amount_mean, inplace=True, limit = 22)\n",
    "# data_test['LoanAmount'].fillna(loan_amount_mean, inplace=True, limit = 5)\n",
    "# data_train.isnull().sum()\n",
    "# # data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Double Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String to number conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_vals(col,col_name,answer1, answer2 ,answer3):\n",
    "#     ixd_1 = np.where(data_train[col_name] == answer1)\n",
    "#     ixd_0 = np.where(data_train[col_name]== answer2)\n",
    "#     ixd_2 = np.where(data_train[col_name]== answer3)\n",
    "#     for i in ixd_1:\n",
    "#         data_train.iloc[i,col] = 1\n",
    "#     for i in ixd_0:\n",
    "#         data_train.iloc[i,col] = 0\n",
    "#     for i in ixd_2:\n",
    "#         data_train.iloc[i,col] = 2\n",
    "\n",
    "# convert_vals(1,'Gender','Male','Female','')\n",
    "# convert_vals(2,'Married','Yes','No','')\n",
    "# convert_vals(4,'Education','Graduate','Not Graduate','')\n",
    "# convert_vals(5,'Self_Employed','No','Yes','')\n",
    "# convert_vals(11,'Property_Area','Semiurban','Rural','Urban')\n",
    "# convert_vals(12,'Loan_Status','Y','N','')\n",
    "\n",
    "# cols = ['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area']\n",
    "\n",
    "# X = data_train[cols]\n",
    "# X = X.astype(float)\n",
    "# X = np.array(X)\n",
    "# # print(X)\n",
    "\n",
    "# Y = data_train['Loan_Status']\n",
    "# Y = Y.astype(float)\n",
    "# Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete everything that's missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Text\"] = df['Title'].fillna('') + ' ' + df['Review Text'].fillna('')\n",
    "# df = df[df['Text'] != ' ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing fancy stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Text'] = df['Text'].str.replace('[^a-zA-Z0-9 \\n\\.]|\\.', '')\n",
    "# df['Text'] = df['Text'].str.lower()\n",
    "# df = df[['Text', 'Rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert back to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]\n",
      " [2.7310e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]\n",
      " [2.7290e-02 0.0000e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]\n",
      " ...\n",
      " [6.0760e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]\n",
      " [1.0959e-01 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]\n",
      " [4.7410e-02 0.0000e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = df.values\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X[:,1], y)\n",
    "# plt.xlabel('x-axis')\n",
    "# plt.ylabel('y-axis')\n",
    "# plt.title('plot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.32000000e-03 1.80000000e+01 2.31000000e+00 ... 3.58157700e+03\n",
      "  6.25235022e+07 1.23505992e+02]\n",
      " [2.73100000e-02 0.00000000e+00 7.07000000e+00 ... 5.63975200e+03\n",
      "  6.25235022e+07 7.63551944e+02]\n",
      " [2.72900000e-02 0.00000000e+00 7.07000000e+00 ... 5.63975200e+03\n",
      "  6.06197221e+07 6.54508270e+01]\n",
      " ...\n",
      " [6.07600000e-02 0.00000000e+00 1.19300000e+01 ... 9.26100000e+03\n",
      "  6.25235022e+07 1.79406144e+02]\n",
      " [1.09590000e-01 0.00000000e+00 1.19300000e+01 ... 9.26100000e+03\n",
      "  6.09072020e+07 2.72097792e+02]\n",
      " [4.74100000e-02 0.00000000e+00 1.19300000e+01 ... 9.26100000e+03\n",
      "  6.25235022e+07 4.89303872e+02]]\n",
      "(506, 26)\n"
     ]
    }
   ],
   "source": [
    "# No dummy\n",
    "def x_polynomial(x, d):\n",
    "    for i in range(1,d):\n",
    "        a = np.concatenate((x,x**(i+1)), axis = 1)\n",
    "    return a\n",
    "X = x_polynomial(X,3)\n",
    "print(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Normalization/Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5.2.1 Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 26)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2.2 Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = (X-np.mean(X, axis = 0))/np.std(X, axis = 0)\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Spliting train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.1 Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n",
    "\n",
    "# # double check the shapes\n",
    "# assert X_train.shape[0] == y_train.shape[0]\n",
    "# # assert len(X_train)  == len(y_train)\n",
    "# assert X_test.shape[0] == y_test.shape[0]\n",
    "# # assert len(X_test) == len(y_test)\n",
    "\n",
    "# print('shapes of X_train, y_train')\n",
    "# print(X_train.shape,y_train.shape)\n",
    "# print('shapes of X_test, y_test')\n",
    "# print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6.2 Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random index \n",
    "import random\n",
    "m = X.shape[0]\n",
    "idx = np.arange(0,m)\n",
    "random.shuffle(idx)\n",
    "\n",
    "# Numpy\n",
    "X = X[idx,:]\n",
    "\n",
    "# Pandas\n",
    "# X = X.iloc[idx,:]\n",
    "\n",
    "# X = X.reset_index()\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X_train, y_train\n",
      "(354, 26) (354,)\n",
      "shapes of X_test, y_test\n",
      "(152, 26) (152,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "m, n = X.shape\n",
    "idx = np.arange(0, m)\n",
    "random.shuffle(idx)\n",
    "percent_train = .7\n",
    "m_train = int(m * percent_train)\n",
    "train_idx = idx[0:m_train]\n",
    "test_idx = idx[m_train:]\n",
    "X_train = X[train_idx,:];\n",
    "X_test = X[test_idx,:];\n",
    "\n",
    "y_train = y[train_idx];\n",
    "y_test = y[test_idx];\n",
    "\n",
    "# double check the shapes\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "# assert len(X_train)  == len(y_train)\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "# assert len(X_test) == len(y_test)\n",
    "\n",
    "print('shapes of X_train, y_train')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test')\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addition of dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X_train, y_train with DUMMY added\n",
      "(354, 28) (354,)\n",
      "shapes of X_test, y_test with DUMMY added\n",
      "(152, 28) (152,)\n"
     ]
    }
   ],
   "source": [
    "# add dummy at X_train\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.concatenate((intercept, X_train), axis=1)\n",
    "\n",
    "# add dummy at X_test\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.concatenate((intercept, X_test), axis=1)\n",
    "\n",
    "print('shapes of X_train, y_train with DUMMY added')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test with DUMMY added')\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
