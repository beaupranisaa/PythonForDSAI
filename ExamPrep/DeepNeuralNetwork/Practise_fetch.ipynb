{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### NO standardddddizeeee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepNeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.second_version import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_boston\n",
    "# import copy\n",
    "# X,y = load_boston(return_X_y = True)\n",
    "# print('shapes of X, y')\n",
    "# print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_breast_cancer\n",
    "# import copy\n",
    "# X,y = load_breast_cancer(return_X_y = True)\n",
    "# print('shapes of X, y')\n",
    "# print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_digits\n",
    "# import copy\n",
    "# X,y = load_digits(return_X_y = True)\n",
    "# print('shapes of X, y')\n",
    "# print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('mnist-original.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X, y\n",
      "(70000, 784) (70000, 1)\n"
     ]
    }
   ],
   "source": [
    "X = mat['data'].T\n",
    "y = mat['label'].T\n",
    "# print(y.shape)\n",
    "print('shapes of X, y')\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X_train, y_train\n",
      "(49000, 784) (49000, 1)\n",
      "shapes of X_test, y_test\n",
      "(21000, 784) (21000, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "#since our train function assumes y to be shape of (n, 1)\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "\n",
    "# double check the shapes\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "# assert len(X_train)  == len(y_train)\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "# assert len(X_test) == len(y_test)\n",
    "\n",
    "print('shapes of X_train, y_train')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test')\n",
    "print(X_test.shape,y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Standardization/Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 One Hot (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 10) (21000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "onehot = preprocessing.OneHotEncoder()\n",
    "\n",
    "#sklearn expects a 2D array thus we have to reshape to (-1, 1)\n",
    "y_train_encode = onehot.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test_encode = onehot.fit_transform(y_test.reshape(-1, 1)).toarray()\n",
    "\n",
    "print(y_train_encode.shape, y_test_encode.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Accuracy Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1 Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calc_accuracy_linear(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    print(\"MSE: \", mean_squared_error(y_test, preds))\n",
    "    print(\"r2 score: \", r2_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def calc_accuracy_binary_classification(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    preds[preds>0.5] = 1\n",
    "    preds[preds<0.5] = 0\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
    "    print(\"Classification Report: \", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a simple accuracy function\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def calc_accuracy_multinomial_classification(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, preds))\n",
    "    print(\"Classification Report: \", classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Add more fancy stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Operation):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def _output(self, inference: bool) -> ndarray: \n",
    "        return np.maximum(0,self.input_)\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        self.output[self.output <= 0] = 0\n",
    "        self.output[self.output > 0] = 1\n",
    "        return output_grad * self.output \n",
    "\n",
    "class LeakyRelu(Operation):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def _output(self, inference: bool) -> ndarray: \n",
    "        return np.maximum(0.2*self.input_,self.input_)\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        dz = np.ones_like(self.output)\n",
    "        dz[self.output<0] = 0.2\n",
    "        return output_grad * dz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryCrossEntropy(Loss):\n",
    "    def __init__(self, eps: float=1e-9):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def _output(self) -> float:\n",
    "\n",
    "        # clipping the softmax output to prevent numeric instability\n",
    "        #numpy.clip(a, a_min, a_max, out=None, **kwargs)\n",
    "        #To prevent extremely large loss values that could lead to numeric instability, \n",
    "        #we’ll clip the output of the softmax function to be no less than 10–7 and no greater than 10^7\n",
    "        self.prediction = np.clip(self.prediction, self.eps, 1 - self.eps)\n",
    "\n",
    "        # actual loss computation\n",
    "        binary_cross_entropy_loss = (\n",
    "            -1.0 * self.target * np.log(self.prediction) - \\\n",
    "                (1.0 - self.target) * np.log(1 - self.prediction)\n",
    "        )\n",
    "        \n",
    "        #return average loss\n",
    "        return np.sum(binary_cross_entropy_loss) / self.prediction.shape[0]\n",
    "\n",
    "    def _input_grad(self) -> ndarray:\n",
    "        #return average grad\n",
    "        return (self.prediction - self.target) / self.prediction.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code: WATCH OUT FOR THE NUMBER OF NEURONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model: Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork(\n",
    "#     layers=[Dense(neurons=13, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=13, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=1,  ##### Neurons = 1\n",
    "#                   activation=Linear(),  ## END WITH LINEAR\n",
    "#                   weight_init=\"glorot\")],\n",
    "#             loss = MeanSquaredError(), \n",
    "# seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model,SGD(lr=0.01) )\n",
    "# #SGDMomentum(lr=0.2, momentum=0.9,final_lr=0.05, decay_type='exponential'))\n",
    "# trainer.fit(X_train, y_train, X_test, y_test,\n",
    "#             epochs = 100,\n",
    "#             eval_every = 10,\n",
    "#             seed=20200720,\n",
    "#             batch_size=60)\n",
    "\n",
    "# print('========= Accuracy ========')\n",
    "# calc_accuracy_linear(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model: Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork(\n",
    "#     layers=[Dense(neurons=20, \n",
    "#                   activation=Tanh(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=5, \n",
    "#                   activation=Tanh(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=1,  ##### Neurons = 1\n",
    "#                   activation=Sigmoid(),  ##### SIGMOID\n",
    "#                   weight_init=\"glorot\")],\n",
    "#             loss = MeanSquaredError(), \n",
    "# seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork(\n",
    "#     layers=[Dense(neurons=20, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=5, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=1, \n",
    "#                   activation=Sigmoid(), ##### SIGMOID\n",
    "#                   weight_init=\"glorot\")],\n",
    "#             loss = BinaryCrossEntropy(), \n",
    "# seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(model,SGDMomentum(lr=0.2, momentum=0.9,\n",
    "#                                     final_lr=0.05, decay_type='exponential'))\n",
    "# trainer.fit(X_train, y_train, X_test, y_test,\n",
    "#             epochs = 50,\n",
    "#             eval_every = 10,\n",
    "#             seed=20200720,\n",
    "#             batch_size=50)\n",
    "\n",
    "# print('========= Accuracy ========')\n",
    "# calc_accuracy_binary_classification(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model: Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=178, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=46, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=10, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = SoftmaxCrossEntropy(), \n",
    "seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 3.697\n",
      "Validation loss after 20 epochs is 3.315\n",
      "Loss increased after epoch 30, final loss was 3.315, using the model from epoch 20\n",
      "========= Accuracy ========\n",
      "Accuracy:  0.10171428571428572\n",
      "Classification Report:                precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      2013\n",
      "         1.0       0.00      0.00      0.00      2320\n",
      "         2.0       0.10      0.41      0.16      2140\n",
      "         3.0       0.10      0.51      0.17      2098\n",
      "         4.0       0.07      0.00      0.00      2047\n",
      "         5.0       0.00      0.00      0.00      1971\n",
      "         6.0       0.09      0.01      0.02      2092\n",
      "         7.0       0.00      0.00      0.00      2206\n",
      "         8.0       0.08      0.00      0.00      2052\n",
      "         9.0       0.10      0.08      0.09      2061\n",
      "\n",
      "    accuracy                           0.10     21000\n",
      "   macro avg       0.05      0.10      0.04     21000\n",
      "weighted avg       0.05      0.10      0.04     21000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, SGDMomentum(lr=0.2, momentum=0.9,\n",
    "                                    final_lr=0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, y_train_encode, X_test, y_test_encode,\n",
    "            epochs = 50,\n",
    "            eval_every = 10,\n",
    "            seed=20200720,\n",
    "            batch_size=60)\n",
    "\n",
    "print('========= Accuracy ========')\n",
    "calc_accuracy_multinomial_classification(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
