{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "#parent class\n",
    "class Optimizer(object):\n",
    "    def __init__(self,\n",
    "                 lr: float = 0.01,\n",
    "                 final_lr: float = 0,\n",
    "                 decay_type: str = 'exponential'):\n",
    "        self.lr = lr\n",
    "        self.final_lr = final_lr  #<----added\n",
    "        self.decay_type = decay_type #<----added\n",
    "\n",
    "    def _setup_decay(self):  #<----added\n",
    "\n",
    "        if not self.decay_type:\n",
    "            return\n",
    "        elif self.decay_type == 'exponential':\n",
    "            self.decay_per_epoch = np.power(self.final_lr / self.lr,\n",
    "                                       1.0 / (self.max_epochs - 1))\n",
    "        elif self.decay_type == 'linear':\n",
    "            self.decay_per_epoch = (self.lr - self.final_lr) / (self.max_epochs - 1)\n",
    "\n",
    "    def _decay_lr(self): #<----added\n",
    "\n",
    "        if not self.decay_type:\n",
    "            return\n",
    "\n",
    "        if self.decay_type == 'exponential':\n",
    "            self.lr *= self.decay_per_epoch\n",
    "\n",
    "        elif self.decay_type == 'linear':\n",
    "            self.lr -= self.decay_per_epoch\n",
    "\n",
    "    def step(self, epoch: int = 0):  #<----added epoch info\n",
    "\n",
    "        for (param, param_grad) in zip(self.net.params(),\n",
    "                                       self.net.param_grads()):\n",
    "            self._update_rule(param=param,\n",
    "                              grad=param_grad)\n",
    "\n",
    "    def _update_rule(self, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "#Stochasitc gradient descent optimizer.  \n",
    "class SGD(Optimizer): \n",
    "    def __init__(self, lr: float = 0.01):\n",
    "        super().__init__(lr)\n",
    "\n",
    "    def step(self):\n",
    "        #params hold w and b\n",
    "        #param_grads hold their gradients\n",
    "        for (param, param_grad) in zip(self.net.params(),\n",
    "                                       self.net.param_grads()):\n",
    "\n",
    "            param -= self.lr * param_grad\n",
    "\n",
    "\n",
    "class SGDMomentum(Optimizer):\n",
    "    def __init__(self,\n",
    "                 lr: float = 0.01,\n",
    "                 final_lr: float = 0,   #<----added\n",
    "                 decay_type: str = None,   #<------added\n",
    "                 momentum: float = 0.9):\n",
    "        super().__init__(lr, final_lr, decay_type)   #<---changed\n",
    "        self.momentum = momentum\n",
    "        self.first = True\n",
    "\n",
    "    def step(self):\n",
    "        if self.first:\n",
    "            self.velocities = [np.zeros_like(param)\n",
    "                               for param in self.net.params()]\n",
    "            self.first = False\n",
    "\n",
    "        for (param, param_grad, velocity) in zip(self.net.params(),\n",
    "                                                 self.net.param_grads(),\n",
    "                                                 self.velocities):\n",
    "            self._update_rule(param=param,\n",
    "                              grad=param_grad,\n",
    "                              velocity=velocity)\n",
    "\n",
    "    def _update_rule(self, **kwargs):\n",
    "\n",
    "            # Update velocity\n",
    "            kwargs['velocity'] *= self.momentum\n",
    "            kwargs['velocity'] += self.lr * kwargs['grad']\n",
    "\n",
    "            # Use this to update parameters\n",
    "            kwargs['param'] -= kwargs['velocity']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
