{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer\n",
    "from copy import deepcopy\n",
    "from typing import Tuple\n",
    "\n",
    "class Trainer(object):\n",
    "    #NeuralNetwork and Optimizer as attributes\n",
    "    def __init__(self,\n",
    "                 net: NeuralNetwork,\n",
    "                 optim: Optimizer):\n",
    "        #Requires a neural network and an optimizer in order for \n",
    "        #training to occur. \n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.best_loss = 1e9  #use for comparing the least amount of loss\n",
    "        \n",
    "        #Assign the neural network as an instance variable to \n",
    "        #the optimizer when the code runs\n",
    "        setattr(self.optim, 'net', self.net)\n",
    "    \n",
    "\n",
    "    # helper function for shuffling\n",
    "    def permute_data(self, X, y):\n",
    "        perm = np.random.permutation(X.shape[0])\n",
    "        return X[perm], y[perm]\n",
    "\n",
    "    # helper function for generating batches\n",
    "    def generate_batches(self,\n",
    "                         X: ndarray,\n",
    "                         y: ndarray,\n",
    "                         size: int = 32) -> Tuple[ndarray]:\n",
    "        #X and y should have same number of rows\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for i in range(0, N, size):\n",
    "            X_batch, y_batch = X[i:i+size], y[i:i+size]\n",
    "            #return a generator that can be loop\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "            \n",
    "    def fit(self, X_train: ndarray, y_train: ndarray,\n",
    "            X_test: ndarray, y_test: ndarray,\n",
    "            epochs: int=100,\n",
    "            eval_every: int=10,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 20200720,\n",
    "            restart: bool = True):\n",
    "        \n",
    "        \n",
    "        setattr(self.optim, 'max_epochs', epochs)\n",
    "        self.optim._setup_decay()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        #for resetting\n",
    "        if restart:\n",
    "            for layer in self.net.layers:\n",
    "                layer.first = True\n",
    "\n",
    "            self.best_loss = 1e9\n",
    "        \n",
    "        #Fits the neural network on the training data for a certain \n",
    "        #number of epochs.\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            if (e+1) % eval_every == 0:\n",
    "                \n",
    "                # for early stopping\n",
    "                # deepcopy is a hardcopy function that make sure it construct a new object (copy() is a shallow copy)\n",
    "                last_model = deepcopy(self.net)\n",
    "\n",
    "            X_train, y_train = self.permute_data(X_train, y_train)\n",
    "\n",
    "            batch_generator = self.generate_batches(X_train, y_train,\n",
    "                                                    batch_size)\n",
    "\n",
    "            for (X_batch, y_batch) in batch_generator:\n",
    "\n",
    "                self.net.train_batch(X_batch, y_batch)\n",
    "\n",
    "                self.optim.step()\n",
    "            \n",
    "            #Every \"eval_every\" epochs, it evaluated the neural network \n",
    "            #on the testing data.\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                test_preds = self.net.forward(X_test, inference=True) #<----inference   #<---make sure validation does not use dropout\n",
    "                loss = self.net.loss.forward(test_preds, y_test)\n",
    "\n",
    "                if loss < self.best_loss:\n",
    "                    print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "                    self.best_loss = loss\n",
    "                #if the validation loss is not lower, it stop and perform early stopping\n",
    "                else:\n",
    "                    print(f\"\"\"Loss increased after epoch {e+1}, final loss was {self.best_loss:.3f}, using the model from epoch {e+1-eval_every}\"\"\")\n",
    "                    self.net = last_model\n",
    "                    # ensure self.optim is still updating self.net\n",
    "                    setattr(self.optim, 'net', self.net)\n",
    "                    break\n",
    "            \n",
    "            #call this at the end of each epoch\n",
    "            if self.optim.final_lr:\n",
    "                self.optim._decay_lr() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
