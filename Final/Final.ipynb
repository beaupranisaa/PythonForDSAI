{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP - Final - 2020\n",
    "\n",
    "## Instruction\n",
    "\n",
    "- Modify this file to be Final-<Your FirstName-[First Letter of Last Name]>, e.g., <code>Final-Chaklam-S.ipynb</code>\n",
    "- This exam accounts for 45% of the overall course assessment.\n",
    "- This exam is open-booked; open-internet.\n",
    "- You ARE NOT allowed to use sklearn or pytorch libraries, unless stated.\n",
    "- The completed exams shall be submitted at the Google Classroom\n",
    "- All code should be **complemented with comments**, unless it's really obvious.  **I and Joe reserve the privilege to give you zero for any part of the question where the benefit of doubt is not justified**\n",
    "\n",
    "## Examination Rules:\n",
    "- For **offline** students, you may leave the room temporarily with the approval and supervision of the proctors. No extra time will be added to the exam in such cases.\n",
    "- For **online** students, you are required to turn on your webcam during the entire period of the exam time\n",
    "- Students will be allowed to leave at the **earliest 45 minutes** after the exam has started\n",
    "- **All work should belong to you**.  A student should NOT engage in the following activities which proctors reserve the right to interpret any of such act as academic dishonesty without questioning:\n",
    "    - Chatting with any human beings physically or via online methods\n",
    "    - Plagiarism of any sort, i.e., copying from internet sources or friends.  **Both copee and copier shall be given a minimum penalty of zero mark for that particular question or the whole exam.**\n",
    "- No make-up exams are allowed.  Special considerations may be given upon a valid reason on unpredictable events such as accidents or serious sickness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (22 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). **Autoencoder**\n",
    "\n",
    "You shall implement autoencoder (NOT variational autoencoders) which shall serve the purpose of dimensionality reduction.  You shall use the Neural Network from scratch code of our class as base.  You are NOT allow to use pyTorch.\n",
    "\n",
    "a). Load the boston data from sklearn, and preprocessing it accordingly (1pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.second_version import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X, y\n",
      "(506, 13) (506,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import copy\n",
    "X,y = load_boston(return_X_y = True)\n",
    "print('shapes of X, y')\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of X_train, y_train\n",
      "(354, 13) (354, 1)\n",
      "shapes of X_test, y_test\n",
      "(152, 13) (152, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "#since our train function assumes y to be shape of (n, 1)\n",
    "y_train, y_test = y_train.reshape(-1, 1), y_test.reshape(-1, 1)\n",
    "\n",
    "# double check the shapes\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "# assert len(X_train)  == len(y_train)\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "# assert len(X_test) == len(y_test)\n",
    "\n",
    "print('shapes of X_train, y_train')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('shapes of X_test, y_test')\n",
    "print(X_test.shape,y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b). The general architecture of the autoencoder is as follows (10pts):\n",
    "\n",
    "                        x = 13 --fc--> 7 --fc--> 3 --fc--> 7 --fc--> 13 = x'\n",
    "    \n",
    "Here fc stands for fully connected / dense layer.  I shall leave the activation, momentum, dropout, learning rate, epochs, number of layers and other parameters as open-ended for you to try out.  For those who don't quite understand what is this neural network does, it is simply squeezing 13 features (the original x) into 7 then to 3.  The left half is called the encoder.  Then from 3, it attempts to reconstruct to 7 and then to 13 (the reconstructed x').  The right half is called the decoder.  Thus the neural network is simply a dimensionality reduction machine. Note that we are NOT working on variational autoencoder in which the encoder splits out mu and sigma, and hence become a generative model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NeuralNetwork(\n",
    "#     layers=[Dense(neurons=13, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=7, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=3, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=7, \n",
    "#                   activation=Sigmoid(),\n",
    "#                   weight_init=\"glorot\",\n",
    "#                   dropout=0.8),\n",
    "#             Dense(neurons=13, \n",
    "#                   activation=Linear(),\n",
    "#                   weight_init=\"glorot\")],\n",
    "#             loss = AutoEndMeanSquaredError(), \n",
    "# seed=20200720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c). Define the loss function as the reconstruction loss, which is simply the the MSE (5pts)\n",
    "\n",
    "$$\\frac{1}{nm}\\sum\\limits_i^n\\sum\\limits_j^m (x_{ij} - x'_{ij})^2$$\n",
    "\n",
    "Here follows our course notation where $m$ is number of sample, and $n$ is number of features.  Note that since we are not working on variational autoencoder, we don't need to care about KL divergence.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.full((4,2), 1)\n",
    "# b = np.full((4,2), 3)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(a-b)\n",
    "# power = np.power((a-b),2)\n",
    "# print(power)\n",
    "# power = np.sum(power,axis = 1)\n",
    "# print('axis = 1',power)\n",
    "# power = np.sum(power,axis = 0)\n",
    "# print('axis = 0',power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override NeuralNetwork at trainer_batch specifically at batch_loss because we arer calculating loss between X_batch and the X_pred and not y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Network\n",
    "class NeuralNetworkAutoEncoder(object):\n",
    "    def __init__(self, \n",
    "                 layers: List[Layer],\n",
    "                 loss: Loss,\n",
    "                 seed: int = 1):\n",
    "        self.layers = layers\n",
    "        self.loss = loss\n",
    "        self.seed = seed\n",
    "        if seed:\n",
    "            for layer in self.layers:\n",
    "                setattr(layer, \"seed\", self.seed)        \n",
    "  \n",
    "    def forward(self, X_batch: ndarray,\n",
    "                inference=False) ->  ndarray:   #<----added inference as param\n",
    "\n",
    "        X_out = X_batch\n",
    "        for layer in self.layers:\n",
    "            X_out = layer.forward(X_out, inference)  #<----added inference as param\n",
    "\n",
    "        return X_out\n",
    "    \n",
    "    def backward(self, loss_grad: ndarray):\n",
    "        grad = loss_grad\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad)\n",
    "            \n",
    "            #you may wonder why I did not return anything\n",
    "            #it's because in Layer.backward, it is appending this value to param_grads to each layer\n",
    "            #this return \"grad\" is simply something it returns\n",
    "  \n",
    "    def train_batch(self,\n",
    "                    X_batch: ndarray,\n",
    "                    y_batch: ndarray,\n",
    "                    inference: bool = False) -> float:  #<-----added inference as param\n",
    "\n",
    "        prediction = self.forward(X_batch, inference)  #<----added inference as param\n",
    "\n",
    "        batch_loss = self.loss.forward(prediction, X_batch)  ##################### changed to self.loss.forward(prediction, X_batch)\n",
    "        loss_grad = self.loss.backward()\n",
    "\n",
    "        self.backward(loss_grad)\n",
    "\n",
    "        return batch_loss\n",
    "    \n",
    "    def params(self):\n",
    "        #get the parameters for the network\n",
    "        #use for updating w and b\n",
    "        for layer in self.layers:\n",
    "            #equivalent for-loop yield\n",
    "            #yield is different from return is that\n",
    "            #it will return a sequence of values\n",
    "            yield from layer.params\n",
    "\n",
    "    def param_grads(self):\n",
    "        #get the gradient of the loss with respect to the parameters\n",
    "        #for the network\n",
    "        #use for updating w and b\n",
    "        for layer in self.layers:\n",
    "            yield from layer.param_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Override Trainer at evaluating test because we are calculating loss between X_test and the X_pred_test and not y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerAutoEncoder(object):\n",
    "    #NeuralNetwork and Optimizer as attributes\n",
    "    def __init__(self,\n",
    "                 net: NeuralNetwork,\n",
    "                 optim: Optimizer):\n",
    "        #Requires a neural network and an optimizer in order for \n",
    "        #training to occur. \n",
    "        self.net = net\n",
    "        self.optim = optim\n",
    "        self.best_loss = 1e9  #use for comparing the least amount of loss\n",
    "        \n",
    "        #Assign the neural network as an instance variable to \n",
    "        #the optimizer when the code runs\n",
    "        setattr(self.optim, 'net', self.net)\n",
    "    \n",
    "\n",
    "    # helper function for shuffling\n",
    "    def permute_data(self, X, y):\n",
    "        perm = np.random.permutation(X.shape[0])\n",
    "        return X[perm], y[perm]\n",
    "\n",
    "    # helper function for generating batches\n",
    "    def generate_batches(self,\n",
    "                         X: ndarray,\n",
    "                         y: ndarray,\n",
    "                         size: int = 32) -> Tuple[ndarray]:\n",
    "        #X and y should have same number of rows\n",
    "        assert X.shape[0] == y.shape[0]\n",
    "\n",
    "        N = X.shape[0]\n",
    "\n",
    "        for i in range(0, N, size):\n",
    "            X_batch, y_batch = X[i:i+size], y[i:i+size]\n",
    "            #return a generator that can be loop\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "            \n",
    "    def fit(self, X_train: ndarray, y_train: ndarray,\n",
    "            X_test: ndarray, y_test: ndarray,\n",
    "            epochs: int=100,\n",
    "            eval_every: int=10,\n",
    "            batch_size: int=32,\n",
    "            seed: int = 20200720,\n",
    "            restart: bool = True):\n",
    "        \n",
    "        \n",
    "        setattr(self.optim, 'max_epochs', epochs)\n",
    "        self.optim._setup_decay()\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        #for resetting\n",
    "        if restart:\n",
    "            for layer in self.net.layers:\n",
    "                layer.first = True\n",
    "\n",
    "            self.best_loss = 1e9\n",
    "        \n",
    "        #Fits the neural network on the training data for a certain \n",
    "        #number of epochs.\n",
    "        for e in range(epochs):\n",
    "            \n",
    "            if (e+1) % eval_every == 0:\n",
    "                \n",
    "                # for early stopping\n",
    "                # deepcopy is a hardcopy function that make sure it construct a new object (copy() is a shallow copy)\n",
    "                last_model = deepcopy(self.net)\n",
    "\n",
    "            X_train, y_train = self.permute_data(X_train, y_train)\n",
    "\n",
    "            batch_generator = self.generate_batches(X_train, y_train,\n",
    "                                                    batch_size)\n",
    "\n",
    "            for (X_batch, y_batch) in batch_generator:\n",
    "\n",
    "                self.net.train_batch(X_batch, y_batch)\n",
    "\n",
    "                self.optim.step()\n",
    "            \n",
    "            #Every \"eval_every\" epochs, it evaluated the neural network \n",
    "            #on the testing data.\n",
    "            if (e+1) % eval_every == 0:\n",
    "\n",
    "                test_preds = self.net.forward(X_test, inference=True) #<----inference   #<---make sure validation does not use dropout\n",
    "                loss = self.net.loss.forward(test_preds, X_test) ################## changed to self.net.loss.forward(test_preds, X_test)\n",
    "\n",
    "                if loss < self.best_loss:\n",
    "                    print(f\"Validation loss after {e+1} epochs is {loss:.3f}\")\n",
    "                    self.best_loss = loss\n",
    "                #if the validation loss is not lower, it stop and perform early stopping\n",
    "                else:\n",
    "                    print(f\"\"\"Loss increased after epoch {e+1}, final loss was {self.best_loss:.3f}, using the model from epoch {e+1-eval_every}\"\"\")\n",
    "                    self.net = last_model\n",
    "                    # ensure self.optim is still updating self.net\n",
    "                    setattr(self.optim, 'net', self.net)\n",
    "                    break\n",
    "            \n",
    "            #call this at the end of each epoch\n",
    "            if self.optim.final_lr:\n",
    "                self.optim._decay_lr() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Loss for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEndMeanSquaredError(Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _output(self) -> float:\n",
    "        loss = np.power((self.target - self.prediction),2)\n",
    "        loss = np.sum(loss, axis = 1)\n",
    "        loss = np.sum(loss,axis = 0)\n",
    "        return loss / (self.prediction.shape[0] * self.prediction.shape[1])\n",
    "\n",
    "    def _input_grad(self) -> ndarray:\n",
    "        grad = (self.prediction - self.target)\n",
    "        return 2.0 * grad / (self.prediction.shape[0] * self.prediction.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Operation):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def _output(self, inference: bool) -> ndarray: \n",
    "        return np.maximum(0,self.input_)\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        self.output[self.output <= 0] = 0\n",
    "        self.output[self.output > 0] = 1\n",
    "        return output_grad * self.output \n",
    "\n",
    "class LeakyRelu(Operation):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def _output(self, inference: bool) -> ndarray: \n",
    "        return np.maximum(0.2*self.input_,self.input_)\n",
    "\n",
    "    def _input_grad(self, output_grad: ndarray) -> ndarray:\n",
    "        dz = np.ones_like(self.output)\n",
    "        dz[self.output<0] = 0.2\n",
    "        return output_grad * dz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d). Execute the model, and print out the reconstruction loss.  Make sure they become smaller!  Also make sure to optimize the parameters (2pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetworkAutoEncoder(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=7, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=3, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=7, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=13, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = AutoEndMeanSquaredError(), \n",
    "seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 1.041\n",
      "Validation loss after 2 epochs is 1.037\n",
      "Validation loss after 3 epochs is 1.034\n",
      "Validation loss after 4 epochs is 1.032\n",
      "Validation loss after 5 epochs is 1.031\n",
      "Validation loss after 6 epochs is 1.030\n",
      "Validation loss after 7 epochs is 1.029\n",
      "Validation loss after 8 epochs is 1.027\n",
      "Validation loss after 9 epochs is 1.025\n",
      "Validation loss after 10 epochs is 1.025\n",
      "Validation loss after 11 epochs is 1.024\n",
      "Validation loss after 12 epochs is 1.023\n",
      "Validation loss after 13 epochs is 1.021\n",
      "Validation loss after 14 epochs is 1.017\n",
      "Validation loss after 15 epochs is 1.014\n",
      "Validation loss after 16 epochs is 1.011\n",
      "Validation loss after 17 epochs is 1.007\n",
      "Validation loss after 18 epochs is 1.000\n",
      "Validation loss after 19 epochs is 0.990\n",
      "Validation loss after 20 epochs is 0.976\n",
      "Validation loss after 21 epochs is 0.957\n",
      "Validation loss after 22 epochs is 0.927\n",
      "Validation loss after 23 epochs is 0.881\n",
      "Validation loss after 24 epochs is 0.825\n",
      "Validation loss after 25 epochs is 0.765\n",
      "Validation loss after 26 epochs is 0.711\n",
      "Validation loss after 27 epochs is 0.666\n",
      "Validation loss after 28 epochs is 0.637\n",
      "Validation loss after 29 epochs is 0.620\n",
      "Validation loss after 30 epochs is 0.609\n",
      "Validation loss after 31 epochs is 0.600\n",
      "Validation loss after 32 epochs is 0.593\n",
      "Validation loss after 33 epochs is 0.587\n",
      "Validation loss after 34 epochs is 0.583\n",
      "Validation loss after 35 epochs is 0.581\n",
      "Validation loss after 36 epochs is 0.578\n",
      "Validation loss after 37 epochs is 0.576\n",
      "Validation loss after 38 epochs is 0.573\n",
      "Validation loss after 39 epochs is 0.571\n",
      "Validation loss after 40 epochs is 0.568\n",
      "Validation loss after 41 epochs is 0.564\n",
      "Validation loss after 42 epochs is 0.560\n",
      "Validation loss after 43 epochs is 0.558\n",
      "Validation loss after 44 epochs is 0.556\n",
      "Loss increased after epoch 45, final loss was 0.556, using the model from epoch 44\n",
      "========= Accuracy ========\n",
      "MSE:  0.6090755186513259\n",
      "r2 score:  0.39330733941019524\n"
     ]
    }
   ],
   "source": [
    "trainer = TrainerAutoEncoder(model,SGDMomentum(lr=0.01, momentum=0.9,final_lr=0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs = 100,\n",
    "            eval_every = 1,\n",
    "            seed=20200720,\n",
    "            batch_size=50)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calc_accuracy_linear(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    print(\"MSE: \", mean_squared_error(X_test, preds))\n",
    "    print(\"r2 score: \", r2_score(X_test, preds))\n",
    "\n",
    "print('========= Accuracy ========')\n",
    "calc_accuracy_linear(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e). Perform predictions and compare (2pts):\n",
    "   - Using the output from a forward pass (see below) on the encoder (NOT the decoder) to predict y\n",
    "   \n",
    "       13 --fc--> 7 --fc--> 3\n",
    "       \n",
    "   \n",
    "   - Using the output from a sklearn PCA with n_components=3 to predict y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=13, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=7, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=3, \n",
    "                  activation=Tanh(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.9),\n",
    "            Dense(neurons=1, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = MeanSquaredError(), \n",
    "seed=20200720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 10 epochs is 526.486\n",
      "Validation loss after 20 epochs is 446.929\n",
      "Validation loss after 30 epochs is 252.303\n",
      "Validation loss after 40 epochs is 84.044\n",
      "Validation loss after 50 epochs is 45.568\n",
      "Validation loss after 60 epochs is 26.214\n",
      "Loss increased after epoch 70, final loss was 26.214, using the model from epoch 60\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model,SGDMomentum(lr=0.00001, momentum=0.9,final_lr=0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs = 100,\n",
    "            eval_every = 10,\n",
    "            seed=20200720,\n",
    "            batch_size=50)\n",
    "\n",
    "preds = model.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Accuracy ========\n",
      "MSE:  44.95388421113917\n",
      "r2 score:  0.39669820628784824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calc_accuracy_linear(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    print(\"MSE: \", mean_squared_error(y_test, preds))\n",
    "    print(\"r2 score: \", r2_score(y_test, preds))\n",
    "    \n",
    "print('========= Accuracy ========')\n",
    "calc_accuracy_linear(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506, 3)\n"
     ]
    }
   ],
   "source": [
    "##### PCA with Sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "boston = load_boston()\n",
    "pca = PCA(3)  # project to 3\n",
    "projected = pca.fit_transform(boston.data)\n",
    "print(boston.data.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss after 1 epochs is 528.260\n",
      "Validation loss after 2 epochs is 517.280\n",
      "Validation loss after 3 epochs is 504.970\n",
      "Validation loss after 4 epochs is 492.093\n",
      "Validation loss after 5 epochs is 478.161\n",
      "Validation loss after 6 epochs is 462.885\n",
      "Validation loss after 7 epochs is 446.352\n",
      "Validation loss after 8 epochs is 429.491\n",
      "Validation loss after 9 epochs is 410.724\n",
      "Validation loss after 10 epochs is 390.383\n",
      "Validation loss after 11 epochs is 368.990\n",
      "Validation loss after 12 epochs is 346.546\n",
      "Validation loss after 13 epochs is 322.522\n",
      "Validation loss after 14 epochs is 298.300\n",
      "Validation loss after 15 epochs is 273.202\n",
      "Validation loss after 16 epochs is 247.610\n",
      "Validation loss after 17 epochs is 222.208\n",
      "Validation loss after 18 epochs is 197.663\n",
      "Validation loss after 19 epochs is 173.882\n",
      "Validation loss after 20 epochs is 152.018\n",
      "Validation loss after 21 epochs is 131.843\n",
      "Validation loss after 22 epochs is 113.869\n",
      "Validation loss after 23 epochs is 98.961\n",
      "Validation loss after 24 epochs is 85.999\n",
      "Validation loss after 25 epochs is 75.915\n",
      "Validation loss after 26 epochs is 67.575\n",
      "Validation loss after 27 epochs is 61.397\n",
      "Validation loss after 28 epochs is 56.595\n",
      "Validation loss after 29 epochs is 52.552\n",
      "Validation loss after 30 epochs is 49.669\n",
      "Validation loss after 31 epochs is 47.600\n",
      "Validation loss after 32 epochs is 45.660\n",
      "Validation loss after 33 epochs is 44.261\n",
      "Validation loss after 34 epochs is 42.875\n",
      "Validation loss after 35 epochs is 41.827\n",
      "Validation loss after 36 epochs is 40.561\n",
      "Validation loss after 37 epochs is 39.147\n",
      "Validation loss after 38 epochs is 38.060\n",
      "Validation loss after 39 epochs is 36.448\n",
      "Validation loss after 40 epochs is 34.915\n",
      "Validation loss after 41 epochs is 33.694\n",
      "Validation loss after 42 epochs is 32.080\n",
      "Validation loss after 43 epochs is 30.764\n",
      "Validation loss after 44 epochs is 29.321\n",
      "Validation loss after 45 epochs is 27.938\n",
      "Validation loss after 46 epochs is 26.555\n",
      "Validation loss after 47 epochs is 26.235\n",
      "Validation loss after 48 epochs is 25.235\n",
      "Validation loss after 49 epochs is 24.137\n",
      "Validation loss after 50 epochs is 23.283\n",
      "Loss increased after epoch 51, final loss was 23.283, using the model from epoch 50\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork(\n",
    "    layers=[Dense(neurons=3, \n",
    "                  activation=Sigmoid(),\n",
    "                  weight_init=\"glorot\",\n",
    "                  dropout=0.8),\n",
    "            Dense(neurons=1, \n",
    "                  activation=Linear(),\n",
    "                  weight_init=\"glorot\")],\n",
    "            loss = MeanSquaredError(), \n",
    "seed=20200720)\n",
    "trainer = Trainer(model,SGDMomentum(lr=0.00001, momentum=0.9,final_lr=0.05, decay_type='exponential'))\n",
    "trainer.fit(X_train, y_train, X_test, y_test,\n",
    "            epochs = 100,\n",
    "            eval_every = 1,\n",
    "            seed=20200720,\n",
    "            batch_size=10)\n",
    "\n",
    "preds = model.forward(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Accuracy ========\n",
      "MSE:  31.11878266352059\n",
      "r2 score:  0.5823716297603367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def calc_accuracy_linear(model, X_test, y_test):    \n",
    "    #getting the accuracy score with testing data\n",
    "    preds = model.forward(X_test)\n",
    "    print(\"MSE: \", mean_squared_error(y_test, preds))\n",
    "    print(\"r2 score: \", r2_score(y_test, preds))\n",
    "    \n",
    "print('========= Accuracy ========')\n",
    "calc_accuracy_linear(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f). Which one is better?  Why? (2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA seems to perform better because PCA does not neglect any information, but only projected it to a specified dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (10 pts)\n",
    "#### Have you learned how to write a class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes :))))))))\n"
     ]
    }
   ],
   "source": [
    "print('Yes :))))))))')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you have been employed as a programmer in a big named car company. Your company has an existing in-house program that helps them to create and design a new car. Their program works great, so you do not need to worry about touching the existing code. Happy day? Not yet.\n",
    "\n",
    "Now that they have hired you, your employer wants you to develop a new program that runs on python (because python is great). Your first task is to write a core class that models a generic car.\n",
    "\n",
    "A certain car has the following properties.\n",
    "- segment: {a, b, c, d}\n",
    "- style: {sedan, crossover, suv, truck}\n",
    "- body-color: {black, white, red, blue, yellow}\n",
    "- init-price: <need to calculate>\n",
    "\n",
    "Once the car has been designed (all the parameter is set), your model should report the initial price. The calculation is straightforward, it is the summation of each properties listed below.\n",
    "\n",
    "- segment \n",
    "  - a: 100\n",
    "  - b: 200\n",
    "  - c: 300\n",
    "  - d: 400\n",
    "- style\n",
    "  - sedan: 500\n",
    "  - crossover: 1000 \n",
    "  - suv: 1200\n",
    "  - truck: 700\n",
    "- body-color:\n",
    "  - black: 10\n",
    "  - white: 99\n",
    "  - red: 150\n",
    "  - blue: 20\n",
    "  - yellow: 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (1pt) Create a class name <code>Car</code>\n",
    "2. (1pt) Write a constructor with no argument.\n",
    "3. (2pts) Each properties must have a <code>get</code> and <code>set</code> method.\n",
    "4. (2pts) Do not forget to check the input in the <code>set</code> method. An error should be thrown when the input is out of range.\n",
    "5. (1pt) Write a <code>report</code> method that \"return\" a string of properties in the following format.\n",
    "segment:<segment\\>|style:<style\\>|body-color:<body-color\\>|init-price:<init-price\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class Car:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_segment(self,segment):\n",
    "        self.segment = segment\n",
    "        self.price_segment = 0\n",
    "        if self.segment == 'a':\n",
    "            self.price_segment = 100\n",
    "        elif self.segment == 'b':\n",
    "            self.price_segment = 200\n",
    "        elif self.segment == 'c':\n",
    "            self.price_segment = 300\n",
    "        if self.segment == 'd':\n",
    "            self.price_segment = 400\n",
    "        \n",
    "    def set_style(self,style):\n",
    "        self.style = style\n",
    "        self.price_style = 0\n",
    "        if self.style == 'sedan':\n",
    "            self.price_style = 500\n",
    "        elif self.style == 'crossover':\n",
    "            self.price_style = 1000\n",
    "        elif self.style == 'suv':\n",
    "            self.price_style = 1200\n",
    "        if self.style == 'truck':\n",
    "            self.price_style = 700\n",
    "        \n",
    "    def set_body_color(self, color):\n",
    "        self.color = color\n",
    "        self.price_color = 0\n",
    "        if self.color == 'black':\n",
    "            self.price_color = 10\n",
    "        elif self.color == 'white':\n",
    "            self.price_color = 99\n",
    "        elif self.color == 'red':\n",
    "            self.price_color = 150\n",
    "        elif self.color == 'blue':\n",
    "            self.price_color = 20  \n",
    "        if self.color == 'yellow':\n",
    "            self.price_color = 20\n",
    "            \n",
    "    def get_segment(self):\n",
    "        return self.segment\n",
    "    \n",
    "    def get_style(self):\n",
    "        return self.style\n",
    "    \n",
    "    def get_body_color(self):\n",
    "        return self.color\n",
    "    \n",
    "    def get_init_price(self):\n",
    "        self.total_price = (self.price_segment + self.price_style + self.price_color)\n",
    "        return (self.price_segment + self.price_style + self.price_color)\n",
    "    \n",
    "    def report(self):\n",
    "        return f\"segment:{self.segment}|style:{self.style}|body-color:{self.color}|init-price:{self.total_price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. (2pts) You get a point for passing this code section.\n",
    "vios = Car()\n",
    "vios.set_segment('b')\n",
    "vios.set_style('sedan')\n",
    "vios.set_body_color('black')\n",
    "\n",
    "assert vios.get_segment() == 'b'\n",
    "assert vios.get_style() == 'sedan'\n",
    "assert vios.get_body_color() == 'black'\n",
    "assert vios.get_init_price() == (200 + 500 + 10)\n",
    "assert vios.report() == \"segment:b|style:sedan|body-color:black|init-price:7\"\n",
    "\n",
    "# print(\"Yay! 2pts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay! 2pts\n"
     ]
    }
   ],
   "source": [
    "print(\"Yay! 2pts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. (1pt) Now, find a way to show that your vios.set_segment('the out of range input') is fully implemented without an error.\n",
    "# hint: try-except, unittest\n",
    "\n",
    "\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The story continues from the previous question. Your company is now trying to adopt a fancier data analytic technique known as Machine Learning. Since your transcript from AIT indicates that you have gone through both ML by Dr. Matt and CP for DSAI by Dr. Chaklam, the task is assigned to your team.\n",
    "\n",
    "You have asked your teammate John and Dave from where ever they are from to collect sample data to perform a classification.\n",
    "\n",
    "Days pass by, you receive an email from Dave. \n",
    "\n",
    "=============================================\n",
    "\n",
    "Dear mate,\n",
    "\n",
    "John and I have uploaded the collected data into \"/Dataset\" folder [here](https://drive.google.com/drive/folders/1QgRtF2eCqayi1yCCKx-2-bkpRBlZaBxT?usp=sharing). The file is named after our name. I remember you told us that John has to collect dataset 1 and I have to collect dataset 2 so I labeled 2 on the last axis to help you in advance. No need to thank (wink wink).\n",
    "\n",
    "By the way, We saved the file in matlab format. I hope it will not cause you any problem since you are an expert from AIT right?\n",
    "\n",
    "sincerely,\n",
    "\n",
    "Dave\n",
    "\n",
    "Your teammate from where ever I am from\n",
    "\n",
    "=============================================\n",
    "\n",
    "\n",
    "1. (1pt) Locate the files and load them.\n",
    "- Hint: https://docs.scipy.org/doc/scipy/reference/tutorial/io.html\n",
    "2. (1pt) Verify the collecting period.\n",
    "3. (1pt) Verify the collected data shape.\n",
    "4. (2pts) Preprocess the data. (Fix the label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "#1.\n",
    "import scipy.io\n",
    "john_mat = scipy.io.loadmat('John.mat')\n",
    "dave_mat = scipy.io.loadmat('Dave.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John, collected period:  ['20201010-20201015']\n",
      "Dave, collected period:  ['20201010-20201015']\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "print(\"John, collected period: \", john_mat['Collected Period'])\n",
    "print(\"Dave, collected period: \", dave_mat['Collected Period'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John, shapes of data\n",
      "(50, 2)\n",
      "Dave, shapes of data\n",
      "(300, 3)\n"
     ]
    }
   ],
   "source": [
    "#3.\n",
    "# print(john_mat)\n",
    "data_john = john_mat['Data']\n",
    "data_dave = dave_mat['Data']\n",
    "# print(y.shape)\n",
    "print('John, shapes of data')\n",
    "print(data_john.shape)\n",
    "print('Dave, shapes of data')\n",
    "print(data_dave.shape)\n",
    "# print(data_dave)\n",
    "# print(data_dave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 3)\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "john_label = np.zeros((data_john.shape[0],1))\n",
    "data_john = np.concatenate((data_john,john_label), axis = 1)\n",
    "print(data_john.shape)\n",
    "data_dave[data_dave[:,2]==2,2] = 1\n",
    "# print(data_john)\n",
    "# print(data_dave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (1pt) Plot the data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f94e31757c0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "plt.scatter(data_john[:,0],data_john[:,1], label ='john')\n",
    "plt.scatter(data_dave[:,0],data_dave[:,1], label ='dave')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (2pts) Plan your strategy. What did you see? What are you going to do? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Your explanation Here\n",
    "As shown above, it is clear to see the imbalance between the two data collections where one of John's contains the relatively smaller amount of data than that one Dave's\n",
    "\n",
    "As for the strategy tackling such classification problem, i go for a model using randomforest method, since random forest has an effective method for estimating missing data and maintains the accuracy  when large proportion of the data are missing.\n",
    "It has methods for balancing errors in data set where classes arre imbalanced "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as for my tree_params, i added 'class_weight' : {0,1/7,1:6/7} as for the data collected by dave is 350 datapoints and one by John is 50 data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (4pts) Develop a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "import random, math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, B, bootstrap_ratio, with_no_replacement=True):\n",
    "        self.B = B\n",
    "        self.bootstrap_ratio = bootstrap_ratio\n",
    "        self.with_no_replacement = with_no_replacement\n",
    "        ######### max_features = 'sqrt'\n",
    "        self.tree_params = {'max_depth': 2, 'max_features': 'sqrt','class_weight' : {0:1/7, 1:6/7}}\n",
    "        self.models = [DecisionTreeClassifier(**self.tree_params) for _ in range(B)]\n",
    "                \n",
    "    def fit(self, X, y):  #<---X_train, y_train\n",
    "        m, n = X.shape\n",
    "\n",
    "        #sample size for each tree\n",
    "        sample_size = int(self.bootstrap_ratio * len(X))\n",
    "\n",
    "        xsamples = np.zeros((B, sample_size, n))\n",
    "        ysamples = np.zeros((B, sample_size))\n",
    "\n",
    "        xsamples_oob = []  #use list because length is not known\n",
    "        ysamples_oob = []\n",
    "\n",
    "        #bootstrapping samples for each model\n",
    "        for i in range(self.B):\n",
    "            oob_idx = []\n",
    "            idxes = []\n",
    "            for j in range(sample_size):\n",
    "                idx = random.randrange(m)\n",
    "                if (self.with_no_replacement):\n",
    "                    while idx in idxes:\n",
    "                        idx = random.randrange(m)\n",
    "                idxes.append(idx)\n",
    "                oob_idx.append(idx)\n",
    "                xsamples[i, j, :] = X[idx]\n",
    "                ysamples[i, j] = y[idx]\n",
    "            mask = np.zeros((m), dtype=bool)\n",
    "            mask[oob_idx] = True\n",
    "            xsamples_oob.append(X[~mask])\n",
    "            ysamples_oob.append(y[~mask])\n",
    "    \n",
    "        #fitting each estimator\n",
    "        oob_score = 0\n",
    "        print(\"======Out of bag score for each tree======\")\n",
    "        for i, model in enumerate(self.models):\n",
    "            \n",
    "            _X = xsamples[i]\n",
    "            _y = ysamples[i]\n",
    "            model.fit(_X, _y)\n",
    "\n",
    "            #calculating oob score\n",
    "            _X_test = np.asarray(xsamples_oob[i])\n",
    "            _y_test = np.asarray(ysamples_oob[i])\n",
    "            yhat = model.predict(_X_test)\n",
    "            oob_score += accuracy_score(_y_test, yhat)\n",
    "            print(f\"Tree {i}\", accuracy_score(_y_test, yhat))\n",
    "        self.avg_oob_score = oob_score / len(self.models)\n",
    "        print(\"======Average out of bag score======\")\n",
    "        print(self.avg_oob_score)\n",
    "    \n",
    "    def predict(self, X): #<---X_test\n",
    "        #make prediction and return the probabilities\n",
    "        predictions = np.zeros((self.B, X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            yhat = model.predict(X)\n",
    "            predictions[i, :] = yhat\n",
    "        return stats.mode(predictions)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 3)\n",
      "(350, 2)\n",
      "(350,)\n"
     ]
    }
   ],
   "source": [
    "data = np.concatenate((data_john,data_dave),axis = 0)\n",
    "print(data.shape)\n",
    "X = data[:,:2]\n",
    "y = data[:,2]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Train =======\n",
      "(245, 2) (245,)\n",
      "======= Test =======\n",
      "(105, 2) (105,)\n"
     ]
    }
   ],
   "source": [
    "# X, y = make_blobs(n_samples=3000, centers=4,random_state=40, cluster_std=1.0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, shuffle=True, random_state=42)\n",
    "\n",
    "print('======= Train =======')\n",
    "print(X_train.shape,y_train.shape)\n",
    "print('======= Test =======')\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Out of bag score for each tree======\n",
      "Tree 0 0.9591836734693877\n",
      "Tree 1 0.9795918367346939\n",
      "Tree 2 0.8571428571428571\n",
      "Tree 3 1.0\n",
      "Tree 4 0.7959183673469388\n",
      "======Average out of bag score======\n",
      "0.9183673469387754\n"
     ]
    }
   ],
   "source": [
    "B= 5\n",
    "model = RandomForest(B=5, bootstrap_ratio=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. (1pt) Show report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        16\n",
      "         1.0       1.00      1.00      1.00        89\n",
      "\n",
      "    accuracy                           1.00       105\n",
      "   macro avg       1.00      1.00      1.00       105\n",
      "weighted avg       1.00      1.00      1.00       105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. (2pts) Is the result good. If not, Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, it seems like a good model. Each of the 5 trees result in high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_tree(model, X, y):\n",
    "    plt.grid()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30)\n",
    "    xx, yy = np.meshgrid(np.linspace(np.min(X[:,0]), np.max(X[:,0]), num=200),\n",
    "                             np.linspace(np.min(X[:,1]), np.max(X[:,1]), num=200))\n",
    "#     print(xx.shape,yy.shape)\n",
    "#     print(X[:, 0].shape, X[:, 1].shape)\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "#     print(Z.shape)\n",
    "    # Create a color plot with the results\n",
    "    n_classes = len(set(y))\n",
    "    contours = plt.contourf(xx, yy, Z, alpha=0.2)\n",
    "\n",
    "# plot_tree(bag, X_train[:,:2], y_train)    \n",
    "    \n",
    "########### only 2 featuresssssssss\n",
    "plot_tree(model, X_test[:,:2], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
